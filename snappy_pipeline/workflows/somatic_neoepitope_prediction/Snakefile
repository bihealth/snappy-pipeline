# -*- coding: utf-8 -*-
"""CUBI Pipeline somatic neoepitope prediction step Snakefile"""

import os

from snappy_pipeline import expand_ref
from snappy_pipeline.workflows.somatic_neoepitope_prediction import (
    SomaticNeoepitopePredictionWorkflow,
)

__author__ = "Pham Gia Cuong"


# Configuration ===============================================================


configfile: "config.yaml"


# Expand "$ref" JSON pointers in configuration (also works for YAML)
config, lookup_paths, config_paths = expand_ref("config.yaml", config)

# WorkflowImpl Object Setup ===================================================
wf = SomaticNeoepitopePredictionWorkflow(workflow, config, lookup_paths, config_paths, os.getcwd())


localrules:
    # Linking files from work/ to output/ should be done locally
    neoepitope_preparation_link_out_run,


rule all:
    input:
        wf.get_result_files(),


# Generic linking out ---------------------------------------------------------


rule neoepitope_preparation_link_out_run:
    input:
        wf.get_input_files("link_out", "run"),
    output:
        wf.get_output_files("link_out", "run"),
    run:
        shell(wf.get_shell_cmd("link_out", "run", wildcards))


rule neoepitope_preparation:
    input:
        unpack(wf.get_input_files("pvacseq","prepare")),
    output:
        **wf.get_output_files("pvacseq","prepare"),
    log:
        **wf.get_log_file("pvacseq","prepare"),
    threads: wf.get_resource("pvacseq","prepare", "threads")
    resources:
        time=wf.get_resource("pvacseq","prepare", "time"),
        memory=wf.get_resource("pvacseq","prepare", "memory"),
        partition=wf.get_resource("pvacseq","prepare", "partition"),
        tmpdir=wf.get_resource("pvacseq","prepare", "tmpdir"),
    params:
        **{"args": wf.get_params("pvacseq","prepare")},
    wrapper:
        wf.wrapper_path("pvactools/combining")
